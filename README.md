3D Skeleton-based Driver Activity Recognition using Self-supervised Learning
============================================================================

Amidst the increasing integration of technology
in car interiors, the risk of driver distraction has become a
critical concern for automotive safety. Addressing this issue
requires robust methods for detecting driver distractions, often
relying on intricate models trained on vast amounts of labeled
data. However, obtaining such labeled data can be expensive
and time-consuming. In this context, self-supervised learning
emerges as a promising approach, leveraging unlabeled data to
learn meaningful representations and reduce dependency on annotated
datasets. In this study, we explore self-supervised learning
methods for 3D skeleton-based driver activity recognition.
We evaluate the performance of our proposed SkelDINO-SAM
method across diverse backbone architectures. Utilizing the
Drive&Act dataset, characterized by its long-tailed distribution
of activity classes, we evaluate the effectiveness of our approach
in addressing challenges associated with real-world scenarios.
Our findings highlight the superiority of transformer-based
backbones, particularly when combined with our SkelDINOSAM
approach. Through extensive experiments and ablation
studies, we demonstrate the efficacy of our method in enhancing
driver secondary task recognition accuracy. Overall, our results
show the efficiency of our approach outperforming the stateof-
the-art method by 11.29%.

![image](https://github.com/davidjlerch/darssl/assets/61084566/f9a4bda1-38f1-46a7-8a49-5e94d24bdefa)
